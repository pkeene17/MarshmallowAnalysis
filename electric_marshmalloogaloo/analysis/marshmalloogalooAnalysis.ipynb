{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a5d3269-bba3-4469-99fc-db183c13f958",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic analyses of Marshmallow data\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import scipy.stats as stats\n",
    "import scipy.io as sio\n",
    "import pandas as pd\n",
    "from nan_scrub import nan_scrub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ece94c7-08b1-44a4-8577-d87df5919d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### column name meanings #####\n",
    "#testData\n",
    "# % run\n",
    "# % trial\n",
    "# % cb: 1 = beaches nback, 2 = gazebos nback\n",
    "# % category_cue: category of the cued scene and competitor (1 = beach, 2 = gazebo)\n",
    "# % category_noncomp: category of the non-competitor item (1 = beach, 2 = gazebo)\n",
    "# % pairnum_cue: which pair within a category the cue and competitor comes from\n",
    "# % pairnum_noncomp: which pair within a category the non-competitor comes from\n",
    "# % pairitem_cue: which item is being shown on this trial (pairmate 1 or pairmate 2) for the cue\n",
    "# % pairitem_noncomp: which item is being shown on this trial (pairmate 1 or pairmate 2) for the non-competitor\n",
    "# % pairid_cue: ID # of this pair (based on all possible combinations) for the cue and competitor\n",
    "# % pairid_noncomp: ID # of this pair (based on all possible combinations) for the non-competitor\n",
    "# % scenenum: which scene is being shown for the cue\n",
    "# % objnum_obj1: which object is being shown for the left item\n",
    "# % objnum_obj2 which object is being shown for the middle item\n",
    "# % objnum_obj3: which object is being shown for the right item\n",
    "# % condition_cue: similarity condition (0-4) of the cue and competitor\n",
    "# % condition_noncomp: similarity condition (0-4) of the non-competitor\n",
    "# % objpos1: which item appeared on the left (1 = target, 2 = competitor, 3 = non-competitor)\n",
    "# % objpos2: which item appeared on the middle (1 = target, 2 = competitor, 3 = non-competitor)\n",
    "# % objpos3:which item appeared on the right (1 = target, 2 = competitor, 3 = non-competitor)\n",
    "# % resp: actual response\n",
    "# % score: 1 = target, 2 = competitor, 3 = non-competitor\n",
    "# % rt: response time (s)\n",
    "\n",
    "#nback\n",
    "# % run\n",
    "# % trial\n",
    "# % category: 1 = beach, 2 = gazebo\n",
    "# % stim: stimulus number shown\n",
    "# % cresp: correct response\n",
    "# % resp: actual response\n",
    "# % acc: accuracy\n",
    "# % rt: response time (s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c37712b-c2ec-4239-8d5d-033a3ae1c60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Helpers #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dabc15c-3fe2-4dfb-8777-0baec03a1fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper to load data\n",
    "def loadData(sn,task=\"both\",robertData=0):\n",
    "    datadir = \"../data/\"\n",
    "    nbackData = np.empty([1000,8])\n",
    "    testData = np.empty([120,23])\n",
    "    subj_str = \"marshmallow_\"+str(sn)\n",
    "    if robertData==1:\n",
    "        if sn<10:\n",
    "            subj_str = \"marshmallow_00\"+str(sn)\n",
    "        else:\n",
    "            subj_str = \"marshmallow_0\"+str(sn)\n",
    "    fullpath_str = datadir+subj_str+\"/\"+subj_str\n",
    "    if np.logical_and(robertData==1,sn==4):\n",
    "        fullpath_str = datadir+subj_str+\"/marshmallow_003\" #dunno how this happened but I suspect it was just an error while running the code\n",
    "    header = sio.loadmat(fullpath_str+\"_header.mat\")\n",
    "    if task!='st':\n",
    "        for irun in range(20):\n",
    "            data = sio.loadmat(fullpath_str+\"_nback_1_\"+str(irun+1)+\".mat\")\n",
    "            nbackData[(irun*50):(irun+1)*50] = data[\"data\"][\"rundata\"][0][0]\n",
    "        nbackData = pd.DataFrame(nbackData,columns=[\"run\",\"trial\",\"category\",\"stim\",\"cresp\",\"resp\",\"acc\",\"rt\"])\n",
    "    if task!='nback':\n",
    "        for irun in range(3):\n",
    "            data = sio.loadmat(fullpath_str+\"_studytest_\"+str(irun+1)+\".mat\")\n",
    "            testData[(irun*40):(irun+1)*40] = data[\"data\"][\"testdata\"][0][0]\n",
    "        testData = pd.DataFrame(testData,columns=[\"run\",\"trial\",\"cat_nb\",\"cat_cue\",\"cat_noncomp\",\n",
    "                                                    \"pairnum_cue\",\"pairnum_noncomp\",\"pairitem_cue\",\"pairitem_noncomp\",\n",
    "                                                    \"pairid_cue\",\"pairid_noncomp\",\n",
    "                                                    \"scenenum\",\"objnum_obj1\",\"objnum_obj2\",\"objnum_obj3\",\"cond_cue\",\n",
    "                                                    \"cond_noncomp\",\"objpos1\",\"objpos2\",\"objpos3\",\"resp\",\"score\",\"rt\"])\n",
    "    return header, nbackData, testData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e99f758-d1e2-4552-ab01-677bfe94480f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#correct when a subject messes up their buttons in the nback (happens fairly often)\n",
    "def nbackRespCorrect(nbackdata,bn):\n",
    "    blockresp = nbackdata.resp[nbackdata.run==bn]\n",
    "    blockcresp = nbackdata.cresp[nbackdata.run==bn]\n",
    "    blockresp[blockresp==2] = 1.0\n",
    "    blockresp[np.isnan(blockresp)] = 2.0\n",
    "    blockacc = blockresp==blockcresp\n",
    "    return blockcresp,blockresp,blockacc.astype(int)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74d67401-bfd2-45be-a6f5-44ad6672404a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#do some descriptive stats on the nback data\n",
    "def nbackSummary(nbackdata,sn,printSubj=0):\n",
    "    mean_nback_acc = np.nanmean(nbackData.acc)\n",
    "    mean_nback_rt = np.nanmean(nbackData.rt)\n",
    "    if printSubj:\n",
    "        print(\"subj\"+str(sn)+\" mean nBack acc = \"+str(mean_nback_acc))\n",
    "        print(\"subj\"+str(sn)+\" mean nBack rt = \"+str(mean_nback_rt))\n",
    "    meanRT = np.zeros(20,dtype=float)\n",
    "    meanAcc = np.zeros(20,dtype=float)\n",
    "    for i in range(20):\n",
    "        if i==13:\n",
    "            if sn==13:\n",
    "                [nbackData.resp[nbackData.run==(i+1)],nbackData.cresp[nbackData.run==(i+1)],nbackData.acc[nbackData.run==(i+1)]]=nbackRespCorrect(nbackData,i+1)\n",
    "        if i==19:\n",
    "            if sn==3:\n",
    "                [nbackData.resp[nbackData.run==(i+1)],nbackData.cresp[nbackData.run==(i+1)],nbackData.acc[nbackData.run==(i+1)]]=nbackRespCorrect(nbackData,i+1)\n",
    "        meanRT[i] = np.nanmean(nbackData.rt[nbackData.run==(i+1)])\n",
    "        meanAcc[i] = np.nanmean(nbackData.acc[nbackData.run==(i+1)])\n",
    "    # if printSubj:\n",
    "    #     print(\"subj\"+str(sn)+\" mean block20 acc = \"+str(meanAcc[13]))\n",
    "    return meanRT,meanAcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f2dd5ee-4e1e-4ff0-bca9-602104e0cad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def studytestSummary(testData,sn,printSubj=0):\n",
    "\t#first, we fix this\n",
    "\ttestData.cat_nb = testData.cat_nb - 1 \n",
    "\ttestData.cat_cue = testData.cat_cue - 1\n",
    "\ttestData.cat_noncomp = testData.cat_noncomp - 1\n",
    "\t#assign catagory labels\n",
    "\tlearned_cat = testData.cat_nb[0]\n",
    "\tnovel_cat = (learned_cat*-1)+1\n",
    "\n",
    "\tmeanAcc = np.nansum(testData.score==1)/120\n",
    "\t#break it up by stimulus condition\n",
    "\tlearned_meanAcc = np.nansum(testData.score[testData.cat_cue==learned_cat]==1)/np.nansum(testData.cat_cue==learned_cat)\n",
    "\tnovel_meanAcc = np.nansum(testData.score[testData.cat_cue==novel_cat]==1)/np.nansum(testData.cat_cue==novel_cat)\n",
    "\tif printSubj:\n",
    "\t\tprint(\"subj\"+str(sn)+\" mean ST acc = \"+str(meanAcc))\n",
    "\t\tprint(\"subj\"+str(sn)+\" learned stimulus mean acc = \"+str(learned_meanAcc))\n",
    "\t\tprint(\"subj\"+str(sn)+\" novel stimulus mean acc = \"+str(novel_meanAcc))\n",
    "\t\t#document nan responses to make sure people are actually doing the task\n",
    "\t\tprint(\"subj\"+str(sn)+\" nan responses = \"+str(np.sum(np.isnan(testData.rt))))\n",
    "\t\tprint(\"\\n\")\n",
    "\t#break it up by block\n",
    "\t#basic stats\n",
    "\tlearned_acc_block = np.zeros(3)\n",
    "\tnovel_acc_block = np.zeros(3)\n",
    "\t#histogram stats\n",
    "\tlearned_num_resps = np.zeros((3,3))\n",
    "\tnovel_num_resps = np.zeros((3,3))\n",
    "\tlearned_rt_resps = np.zeros((3,3))\n",
    "\tnovel_rt_resps = np.zeros((3,3))\n",
    "\t#rt stats\n",
    "\tlearned_rt_block = np.zeros(3)\n",
    "\tnovel_rt_block = np.zeros(3)\n",
    "\tfor i in range(3):\n",
    "\t\tlearned_rt_block[i] = np.nanmean(testData.rt[np.logical_and(testData.cat_cue==learned_cat,testData.run==(i+1))])\n",
    "\t\tnovel_rt_block[i] = np.nanmean(testData.rt[np.logical_and(testData.cat_cue==novel_cat,testData.run==(i+1))])\n",
    "\t\tlearned_acc_block[i] = np.nansum(testData.score[np.logical_and(testData.cat_cue==learned_cat,testData.run==(i+1))]==1)/np.nansum(np.logical_and(testData.cat_cue==learned_cat,testData.run==(i+1)))\n",
    "\t\tnovel_acc_block[i] = np.nansum(testData.score[np.logical_and(testData.cat_cue==novel_cat,testData.run==(i+1))]==1)/np.nansum(np.logical_and(testData.cat_cue==novel_cat,testData.run==(i+1)))\n",
    "\t\tlearned_num_resps[0,i] = np.nansum(testData.score[np.logical_and(testData.cat_cue==learned_cat,testData.run==(i+1))]==1)\n",
    "\t\tlearned_num_resps[1,i] = np.nansum(testData.score[np.logical_and(testData.cat_cue==learned_cat,testData.run==(i+1))]==2)\n",
    "\t\tlearned_num_resps[2,i] = np.nansum(testData.score[np.logical_and(testData.cat_cue==learned_cat,testData.run==(i+1))]==3)\n",
    "\t\tnovel_num_resps[0,i] = np.nansum(testData.score[np.logical_and(testData.cat_cue==novel_cat,testData.run==(i+1))]==1)\n",
    "\t\tnovel_num_resps[1,i] = np.nansum(testData.score[np.logical_and(testData.cat_cue==novel_cat,testData.run==(i+1))]==2)\n",
    "\t\tnovel_num_resps[2,i] = np.nansum(testData.score[np.logical_and(testData.cat_cue==novel_cat,testData.run==(i+1))]==3)\n",
    "\t\t#these sometimes throw a warning because some subjects did not chose the competitor/noncompetior for whole blocks, so theres nothing to average\n",
    "\t\tlearned_rt_resps[0,i] = np.nanmean(testData.rt[np.logical_and(np.logical_and(testData.cat_cue==learned_cat,testData.run==(i+1)),testData.score==1)])\n",
    "\t\tlearned_rt_resps[1,i] = np.nanmean(testData.rt[np.logical_and(np.logical_and(testData.cat_cue==learned_cat,testData.run==(i+1)),testData.score==2)])\n",
    "\t\tlearned_rt_resps[2,i] = np.nanmean(testData.rt[np.logical_and(np.logical_and(testData.cat_cue==learned_cat,testData.run==(i+1)),testData.score==3)])\n",
    "\t\tnovel_rt_resps[0,i] = np.nanmean(testData.rt[np.logical_and(np.logical_and(testData.cat_cue==novel_cat,testData.run==(i+1)),testData.score==1)])\n",
    "\t\tnovel_rt_resps[1,i] = np.nanmean(testData.rt[np.logical_and(np.logical_and(testData.cat_cue==novel_cat,testData.run==(i+1)),testData.score==2)])\n",
    "\t\tnovel_rt_resps[2,i] = np.nanmean(testData.rt[np.logical_and(np.logical_and(testData.cat_cue==novel_cat,testData.run==(i+1)),testData.score==3)])\n",
    "\treturn learned_acc_block,novel_acc_block,learned_num_resps,novel_num_resps,learned_rt_block,novel_rt_block,learned_rt_resps,novel_rt_resps,learned_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc40bde5-8c3a-4e28-af97-180394655905",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assumes levels of responses are balanced (wont work with nback)\n",
    "#Adapted from this source: https://psychology.stackexchange.com/questions/13386/in-a-forced-choice-task-what-proportion-of-responses-is-above-chance-level\n",
    "def binomial_cutoff(ntrials,npermutations,p_cutoff,num_levels):\n",
    "\t#randomly generate a 'correct' set of responses\n",
    "\texpected = np.random.choice(num_levels,ntrials)\n",
    "\t#randomly generate a responses to many runs of the experiment\n",
    "\trandom_resps = np.random.choice(num_levels,[npermutations,ntrials])\n",
    "\t#get mean accuracy for each random run\n",
    "\tpercent_correct = np.nansum(random_resps==expected,1)/ntrials\n",
    "\t#find the point on the distribution of accuracies where anything less would be statistically significant\n",
    "\tcutoff = np.quantile(percent_correct,1-p_cutoff)\n",
    "\treturn cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1bd1e02-a762-4114-818d-fdb59daccced",
   "metadata": {},
   "outputs": [],
   "source": [
    "############# DRIVER ##############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c607a75-ed7f-45a7-bc20-d59f5bd8565e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc cutoff =  0.4083333333333333\n"
     ]
    }
   ],
   "source": [
    "#set constants\n",
    "exclusion = 1 #1 = exclude subjects below chance perfomance on the association task 0 = no exclusion\n",
    "printSubj = 1 #toggle whether to print individual subject's behavioral performance\n",
    "show_plot = 0 #toggle whether to show plots or just save as pdfs\n",
    "save_plot = 1 #toggle whether to save plots (useful if you're fucking around)\n",
    "nsubj = 29\n",
    "nRuns_nback = 20\n",
    "nRuns_ST = 3\n",
    "figure_dir = \"../figures/\"\n",
    "#preallocate data frames\n",
    "meanRT_nback = np.zeros((nsubj,nRuns_nback))\n",
    "meanAcc_nback = np.zeros((nsubj,nRuns_nback))\n",
    "meanAcc_learned = np.zeros((nsubj,nRuns_ST))\n",
    "meanAcc_novel = np.zeros((nsubj,nRuns_ST))\n",
    "meanRT_learned = np.zeros((nsubj,nRuns_ST))\n",
    "meanRT_novel = np.zeros((nsubj,nRuns_ST))\n",
    "histData_learned = np.zeros((nsubj,3,nRuns_ST))\n",
    "histData_novel = np.zeros((nsubj,3,nRuns_ST))\n",
    "rtData_learned = np.zeros((nsubj,3,nRuns_ST))\n",
    "rtData_novel = np.zeros((nsubj,3,nRuns_ST))\n",
    "category_learned = np.zeros(nsubj)\n",
    "fb_select = np.ones(nsubj)\n",
    "#determine what \"chance\" performance cutoff is\n",
    "cutoff = binomial_cutoff(120,10000,0.05,3)\n",
    "fb_cutoff = binomial_cutoff(40,10000,0.05,3)\n",
    "print(\"acc cutoff = \",cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "617b1119-8872-44a8-a2a9-eff7be95337a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subj1 mean nBack acc = 0.919\n",
      "subj1 mean nBack rt = 0.7000621329928249\n",
      "subj1 mean ST acc = 0.9583333333333334\n",
      "subj1 learned stimulus mean acc = 0.95\n",
      "subj1 novel stimulus mean acc = 0.9666666666666667\n",
      "subj1 nan responses = 0\n",
      "\n",
      "\n",
      "subj2 mean nBack acc = 0.87\n",
      "subj2 mean nBack rt = 0.6328863654648877\n",
      "subj2 mean ST acc = 0.85\n",
      "subj2 learned stimulus mean acc = 0.8333333333333334\n",
      "subj2 novel stimulus mean acc = 0.8666666666666667\n",
      "subj2 nan responses = 0\n",
      "\n",
      "\n",
      "subj3 mean nBack acc = 0.832\n",
      "subj3 mean nBack rt = 0.6548513134265106\n",
      "subj3 mean ST acc = 0.7083333333333334\n",
      "subj3 learned stimulus mean acc = 0.7166666666666667\n",
      "subj3 novel stimulus mean acc = 0.7\n",
      "subj3 nan responses = 1\n",
      "\n",
      "\n",
      "subj4 mean nBack acc = 0.835\n",
      "subj4 mean nBack rt = 0.44513870588070953\n",
      "subj4 mean ST acc = 0.35\n",
      "subj4 learned stimulus mean acc = 0.3333333333333333\n",
      "subj4 novel stimulus mean acc = 0.36666666666666664\n",
      "subj4 nan responses = 0\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9d/64h6bpdx6wld4v9tw1jq1yqr0000gp/T/ipykernel_2627/2322959653.py:47: RuntimeWarning: Mean of empty slice\n",
      "  learned_rt_resps[2,i] = np.nanmean(testData.rt[np.logical_and(np.logical_and(testData.cat_cue==learned_cat,testData.run==(i+1)),testData.score==3)])\n",
      "/var/folders/9d/64h6bpdx6wld4v9tw1jq1yqr0000gp/T/ipykernel_2627/2322959653.py:46: RuntimeWarning: Mean of empty slice\n",
      "  learned_rt_resps[1,i] = np.nanmean(testData.rt[np.logical_and(np.logical_and(testData.cat_cue==learned_cat,testData.run==(i+1)),testData.score==2)])\n",
      "/var/folders/9d/64h6bpdx6wld4v9tw1jq1yqr0000gp/T/ipykernel_2627/2322959653.py:49: RuntimeWarning: Mean of empty slice\n",
      "  novel_rt_resps[1,i] = np.nanmean(testData.rt[np.logical_and(np.logical_and(testData.cat_cue==novel_cat,testData.run==(i+1)),testData.score==2)])\n",
      "/var/folders/9d/64h6bpdx6wld4v9tw1jq1yqr0000gp/T/ipykernel_2627/2322959653.py:50: RuntimeWarning: Mean of empty slice\n",
      "  novel_rt_resps[2,i] = np.nanmean(testData.rt[np.logical_and(np.logical_and(testData.cat_cue==novel_cat,testData.run==(i+1)),testData.score==3)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subj5 mean nBack acc = 0.869\n",
      "subj5 mean nBack rt = 0.6161966323620858\n",
      "subj5 mean ST acc = 0.725\n",
      "subj5 learned stimulus mean acc = 0.7333333333333333\n",
      "subj5 novel stimulus mean acc = 0.7166666666666667\n",
      "subj5 nan responses = 1\n",
      "\n",
      "\n",
      "subj6 mean nBack acc = 0.913\n",
      "subj6 mean nBack rt = 0.6623912675304281\n",
      "subj6 mean ST acc = 0.825\n",
      "subj6 learned stimulus mean acc = 0.8333333333333334\n",
      "subj6 novel stimulus mean acc = 0.8166666666666667\n",
      "subj6 nan responses = 0\n",
      "\n",
      "\n",
      "subj7 mean nBack acc = 0.844\n",
      "subj7 mean nBack rt = 0.7114858580251782\n",
      "subj7 mean ST acc = 0.775\n",
      "subj7 learned stimulus mean acc = 0.8\n",
      "subj7 novel stimulus mean acc = 0.75\n",
      "subj7 nan responses = 0\n",
      "\n",
      "\n",
      "subj8 mean nBack acc = 0.92\n",
      "subj8 mean nBack rt = 0.6865283540634003\n",
      "subj8 mean ST acc = 0.6\n",
      "subj8 learned stimulus mean acc = 0.5666666666666667\n",
      "subj8 novel stimulus mean acc = 0.6333333333333333\n",
      "subj8 nan responses = 0\n",
      "\n",
      "\n",
      "subj9 mean nBack acc = 0.83\n",
      "subj9 mean nBack rt = 0.6548215112658103\n",
      "subj9 mean ST acc = 0.725\n",
      "subj9 learned stimulus mean acc = 0.7666666666666667\n",
      "subj9 novel stimulus mean acc = 0.6833333333333333\n",
      "subj9 nan responses = 0\n",
      "\n",
      "\n",
      "subj10 mean nBack acc = 0.735\n",
      "subj10 mean nBack rt = 0.4078832878433261\n",
      "subj10 mean ST acc = 0.19166666666666668\n",
      "subj10 learned stimulus mean acc = 0.23333333333333334\n",
      "subj10 novel stimulus mean acc = 0.15\n",
      "subj10 nan responses = 44\n",
      "\n",
      "\n",
      "subj11 mean nBack acc = 0.909\n",
      "subj11 mean nBack rt = 0.6427604260445386\n",
      "subj11 mean ST acc = 0.8\n",
      "subj11 learned stimulus mean acc = 0.8\n",
      "subj11 novel stimulus mean acc = 0.8\n",
      "subj11 nan responses = 0\n",
      "\n",
      "\n",
      "subj12 mean nBack acc = 0.881\n",
      "subj12 mean nBack rt = 0.6585180356799638\n",
      "subj12 mean ST acc = 0.7416666666666667\n",
      "subj12 learned stimulus mean acc = 0.8\n",
      "subj12 novel stimulus mean acc = 0.6833333333333333\n",
      "subj12 nan responses = 0\n",
      "\n",
      "\n",
      "subj13 mean nBack acc = 0.743\n",
      "subj13 mean nBack rt = 0.6786933220567533\n",
      "subj13 mean ST acc = 0.5666666666666667\n",
      "subj13 learned stimulus mean acc = 0.5166666666666667\n",
      "subj13 novel stimulus mean acc = 0.6166666666666667\n",
      "subj13 nan responses = 0\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9d/64h6bpdx6wld4v9tw1jq1yqr0000gp/T/ipykernel_2627/2322959653.py:34: RuntimeWarning: Mean of empty slice\n",
      "  learned_rt_block[i] = np.nanmean(testData.rt[np.logical_and(testData.cat_cue==learned_cat,testData.run==(i+1))])\n",
      "/var/folders/9d/64h6bpdx6wld4v9tw1jq1yqr0000gp/T/ipykernel_2627/2322959653.py:35: RuntimeWarning: Mean of empty slice\n",
      "  novel_rt_block[i] = np.nanmean(testData.rt[np.logical_and(testData.cat_cue==novel_cat,testData.run==(i+1))])\n",
      "/var/folders/9d/64h6bpdx6wld4v9tw1jq1yqr0000gp/T/ipykernel_2627/2322959653.py:45: RuntimeWarning: Mean of empty slice\n",
      "  learned_rt_resps[0,i] = np.nanmean(testData.rt[np.logical_and(np.logical_and(testData.cat_cue==learned_cat,testData.run==(i+1)),testData.score==1)])\n",
      "/var/folders/9d/64h6bpdx6wld4v9tw1jq1yqr0000gp/T/ipykernel_2627/2322959653.py:48: RuntimeWarning: Mean of empty slice\n",
      "  novel_rt_resps[0,i] = np.nanmean(testData.rt[np.logical_and(np.logical_and(testData.cat_cue==novel_cat,testData.run==(i+1)),testData.score==1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subj14 mean nBack acc = 0.879\n",
      "subj14 mean nBack rt = 0.7221935813591595\n",
      "subj14 mean ST acc = 0.8666666666666667\n",
      "subj14 learned stimulus mean acc = 0.9\n",
      "subj14 novel stimulus mean acc = 0.8333333333333334\n",
      "subj14 nan responses = 0\n",
      "\n",
      "\n",
      "subj15 mean nBack acc = 0.776\n",
      "subj15 mean nBack rt = 0.6667170393569896\n",
      "subj15 mean ST acc = 0.5916666666666667\n",
      "subj15 learned stimulus mean acc = 0.65\n",
      "subj15 novel stimulus mean acc = 0.5333333333333333\n",
      "subj15 nan responses = 0\n",
      "\n",
      "\n",
      "subj16 mean nBack acc = 0.896\n",
      "subj16 mean nBack rt = 0.6090529574181094\n",
      "subj16 mean ST acc = 0.35\n",
      "subj16 learned stimulus mean acc = 0.43333333333333335\n",
      "subj16 novel stimulus mean acc = 0.26666666666666666\n",
      "subj16 nan responses = 0\n",
      "\n",
      "\n",
      "subj17 mean nBack acc = 0.816\n",
      "subj17 mean nBack rt = 0.6538326720384762\n",
      "subj17 mean ST acc = 0.7\n",
      "subj17 learned stimulus mean acc = 0.6666666666666666\n",
      "subj17 novel stimulus mean acc = 0.7333333333333333\n",
      "subj17 nan responses = 1\n",
      "\n",
      "\n",
      "subj18 mean nBack acc = 0.93\n",
      "subj18 mean nBack rt = 0.6079253027785525\n",
      "subj18 mean ST acc = 0.7083333333333334\n",
      "subj18 learned stimulus mean acc = 0.75\n",
      "subj18 novel stimulus mean acc = 0.6666666666666666\n",
      "subj18 nan responses = 0\n",
      "\n",
      "\n",
      "subj19 mean nBack acc = 0.824\n",
      "subj19 mean nBack rt = 0.6152893944565738\n",
      "subj19 mean ST acc = 0.75\n",
      "subj19 learned stimulus mean acc = 0.8333333333333334\n",
      "subj19 novel stimulus mean acc = 0.6666666666666666\n",
      "subj19 nan responses = 0\n",
      "\n",
      "\n",
      "subj20 mean nBack acc = 0.822\n",
      "subj20 mean nBack rt = 0.5575767426997977\n",
      "subj20 mean ST acc = 0.35\n",
      "subj20 learned stimulus mean acc = 0.23333333333333334\n",
      "subj20 novel stimulus mean acc = 0.4666666666666667\n",
      "subj20 nan responses = 0\n",
      "\n",
      "\n",
      "subj21 mean nBack acc = 0.751\n",
      "subj21 mean nBack rt = 0.6805676515667648\n",
      "subj21 mean ST acc = 0.7166666666666667\n",
      "subj21 learned stimulus mean acc = 0.7666666666666667\n",
      "subj21 novel stimulus mean acc = 0.6666666666666666\n",
      "subj21 nan responses = 0\n",
      "\n",
      "\n",
      "subj22 mean nBack acc = 0.506\n",
      "subj22 mean nBack rt = 0.11784848135455651\n",
      "subj22 mean ST acc = 0.2916666666666667\n",
      "subj22 learned stimulus mean acc = 0.36666666666666664\n",
      "subj22 novel stimulus mean acc = 0.21666666666666667\n",
      "subj22 nan responses = 1\n",
      "\n",
      "\n",
      "subj23 mean nBack acc = 0.751\n",
      "subj23 mean nBack rt = 0.6726131746768526\n",
      "subj23 mean ST acc = 0.36666666666666664\n",
      "subj23 learned stimulus mean acc = 0.35\n",
      "subj23 novel stimulus mean acc = 0.38333333333333336\n",
      "subj23 nan responses = 1\n",
      "\n",
      "\n",
      "subj24 mean nBack acc = 0.64\n",
      "subj24 mean nBack rt = 0.6542534400988602\n",
      "subj24 mean ST acc = 0.25\n",
      "subj24 learned stimulus mean acc = 0.3\n",
      "subj24 novel stimulus mean acc = 0.2\n",
      "subj24 nan responses = 4\n",
      "\n",
      "\n",
      "subj25 mean nBack acc = 0.244\n",
      "subj25 mean nBack rt = 0.5990791327402746\n",
      "subj25 mean ST acc = 0.31666666666666665\n",
      "subj25 learned stimulus mean acc = 0.31666666666666665\n",
      "subj25 novel stimulus mean acc = 0.31666666666666665\n",
      "subj25 nan responses = 8\n",
      "\n",
      "\n",
      "subj26 mean nBack acc = 0.899\n",
      "subj26 mean nBack rt = 0.6048937593429047\n",
      "subj26 mean ST acc = 0.6666666666666666\n",
      "subj26 learned stimulus mean acc = 0.6333333333333333\n",
      "subj26 novel stimulus mean acc = 0.7\n",
      "subj26 nan responses = 0\n",
      "\n",
      "\n",
      "subj27 mean nBack acc = 0.824\n",
      "subj27 mean nBack rt = 0.45824009359896534\n",
      "subj27 mean ST acc = 0.7333333333333333\n",
      "subj27 learned stimulus mean acc = 0.7333333333333333\n",
      "subj27 novel stimulus mean acc = 0.7333333333333333\n",
      "subj27 nan responses = 0\n",
      "\n",
      "\n",
      "subj28 mean nBack acc = 0.775\n",
      "subj28 mean nBack rt = 0.6870079809601388\n",
      "subj28 mean ST acc = 0.44166666666666665\n",
      "subj28 learned stimulus mean acc = 0.4666666666666667\n",
      "subj28 novel stimulus mean acc = 0.4166666666666667\n",
      "subj28 nan responses = 1\n",
      "\n",
      "\n",
      "subj29 mean nBack acc = 0.84\n",
      "subj29 mean nBack rt = 0.6442832139491733\n",
      "subj29 mean ST acc = 0.6\n",
      "subj29 learned stimulus mean acc = 0.5\n",
      "subj29 novel stimulus mean acc = 0.7\n",
      "subj29 nan responses = 0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#load data by subject\n",
    "#if this box throws a warning, it is because it's trying to calculate the mean number of incorrect targets \n",
    "#(or correct cometitors, etc) and none of those exist in that block. You can safely ignore the warning\n",
    "for sn in range(nsubj):\n",
    "    subjID = sn+1\n",
    "    [header,nbackData,testData] = loadData(subjID)\n",
    "    # if subjID>40:\n",
    "    # \tsubjID = subjID-40\n",
    "    # \t[header,nbackData,testData] = loadData(subjID,robertData=1)\n",
    "    # else:\n",
    "    # \t[header,nbackData,testData] = loadData(subjID)\n",
    "\n",
    "    #nback analysis\n",
    "    [meanRT_nback[sn], meanAcc_nback[sn]] = nbackSummary(nbackData,subjID,printSubj)\n",
    "\n",
    "    #testData analysis\n",
    "    [meanAcc_learned[sn], meanAcc_novel[sn],histData_learned[sn],histData_novel[sn],\n",
    "    meanRT_learned[sn],meanRT_novel[sn],rtData_learned[sn],rtData_novel[sn],category_learned[sn]] = studytestSummary(testData,subjID,printSubj)\n",
    "    \n",
    "    #apriori below chance exclusion criteria\n",
    "    if exclusion:\n",
    "        if np.nansum(testData.score==1)/120 < cutoff:\n",
    "            fb_select[sn] = 0\n",
    "            meanAcc_learned[sn,:] = np.nan\n",
    "            meanAcc_novel[sn,:] = np.nan\n",
    "            histData_learned[sn,:,:] = np.nan\n",
    "            histData_novel[sn,:,:] = np.nan\n",
    "            meanAcc_nback[sn,:] = np.nan\n",
    "            meanRT_nback[sn,:] = np.nan\n",
    "            meanRT_learned[sn,:] = np.nan\n",
    "            meanRT_novel[sn,:] = np.nan\n",
    "            rtData_learned[sn,:] = np.nan\n",
    "            rtData_novel[sn,:] = np.nan\n",
    "        elif np.nansum(testData.score[0:40]==1)/40 < fb_cutoff:\n",
    "            fb_select[sn] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5fd1d0e-d51d-49ce-8079-57719f83a451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nsubj after exclusion =  21\n"
     ]
    }
   ],
   "source": [
    "#recalculate sample size after exclusion\n",
    "nsubj = nsubj-np.sum(np.isnan(np.mean(meanAcc_learned,1)))\n",
    "print('nsubj after exclusion = ',nsubj)\n",
    "# #because of the error when originally running this the stimuli arent balanced so I'm just excluding all of roberts data for this single analysis since thats the most principled way I can balance this\n",
    "# category_learned[40:52] = np.nan \n",
    "# print(np.nansum(category_learned==1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9d22ddc-3eca-40ac-8f9c-13c96c17efbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Familiar accuracy = 0.7246031746031746  Unfamiliar accuracy = 0.7087301587301587\n",
      "Familiar vs unfamiliar acc ttest:  [0.843874 0.40872 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9d/64h6bpdx6wld4v9tw1jq1yqr0000gp/T/ipykernel_2627/1174606237.py:5: RuntimeWarning: Mean of empty slice\n",
      "  print(\"Familiar vs unfamiliar acc ttest: \",np.round(stats.ttest_rel(np.nanmean(meanAcc_learned,1),np.nanmean(meanAcc_novel,1),nan_policy='omit'),6))\n",
      "/var/folders/9d/64h6bpdx6wld4v9tw1jq1yqr0000gp/T/ipykernel_2627/1174606237.py:10: RuntimeWarning: Mean of empty slice\n",
      "  plt.errorbar([0,1],[np.nanmean(meanAcc_learned),np.nanmean(meanAcc_novel)],yerr=[np.nanstd(np.nanmean(meanAcc_learned,1))/np.sqrt(nsubj),np.nanstd(np.nanmean(meanAcc_novel,1))/np.sqrt(nsubj)],color='k')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print the basics\n",
    "print(\"Familiar accuracy = \"+str(np.nanmean(meanAcc_learned)),\" Unfamiliar accuracy = \"+str(np.nanmean(meanAcc_novel)))\n",
    "\n",
    "#ttest of mean accuracy distributions between familiar and unfamiliar stimuli\n",
    "print(\"Familiar vs unfamiliar acc ttest: \",np.round(stats.ttest_rel(np.nanmean(meanAcc_learned,1),np.nanmean(meanAcc_novel,1),nan_policy='omit'),6))\n",
    "#plot difference between familiar and unfamiliar accuracy means\n",
    "fig = plt.figure()\n",
    "plt.bar([0,1],[np.nanmean(meanAcc_learned),np.nanmean(meanAcc_novel)],color=['blue','m'])\n",
    "#error term is SEM\n",
    "plt.errorbar([0,1],[np.nanmean(meanAcc_learned),np.nanmean(meanAcc_novel)],yerr=[np.nanstd(np.nanmean(meanAcc_learned,1))/np.sqrt(nsubj),np.nanstd(np.nanmean(meanAcc_novel,1))/np.sqrt(nsubj)],color='k')\n",
    "plt.xlabel(\"stimulus condition\")\n",
    "plt.xticks([0,1],[\"familiar\",\"unfamiliar\"])\n",
    "plt.ylabel(\"mean accuracy (%)\")\n",
    "plt.yticks([0,.2,.4,.6,.8,1],[0,20,40,60,80,100])\n",
    "plt.title(\"Mean accuracy by condition\")\n",
    "#plt.scatter([0.5],[.8],marker='*',color='k')\n",
    "if save_plot:\n",
    "\tplt.savefig(figure_dir+'acc_diff_familiar_vs_nonfamiliar.pdf',format='pdf')\n",
    "if show_plot:\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bddea07b-9d79-4378-9d8f-03dc1de3c6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Plot distribution of responses by condition #######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4eec0d43-1aaa-4fdb-8cb5-d84048a9aefb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Familiar vs unfamiliar target resps ttest:  [0.843874 0.40872 ]\n",
      "Familiar vs unfamiliar competitor resps ttest:  [-0.801203  0.43243 ]\n",
      "Familiar vs unfamiliar noncompetitor resps ttest:  [0.197353 0.845543]\n",
      "Familiar anova:  F_onewayResult(statistic=37.60150704485207, pvalue=2.176586920727809e-12)\n",
      "Unfamiliar anova:  F_onewayResult(statistic=37.52128200158208, pvalue=2.2707458757469298e-12)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot histograms of responses for each condition\n",
    "#ttest between familiar and unfamiliar target #dunno why I did this but it looks pretty I guess\n",
    "print(\"Familiar vs unfamiliar target resps ttest: \",np.round(stats.ttest_rel(np.sum(histData_learned,2)[:,0],np.sum(histData_novel,2)[:,0],nan_policy='omit'),6))\n",
    "#ttest between familiar and unfamiliar competitor\n",
    "print(\"Familiar vs unfamiliar competitor resps ttest: \",np.round(stats.ttest_rel(np.sum(histData_learned,2)[:,1],np.sum(histData_novel,2)[:,1],nan_policy='omit'),6))\n",
    "#ttest between familiar and unfamiliar noncompetitor\n",
    "print(\"Familiar vs unfamiliar noncompetitor resps ttest: \",np.round(stats.ttest_rel(np.sum(histData_learned,2)[:,2],np.sum(histData_novel,2)[:,2],nan_policy = 'omit'),6))\n",
    "#anova between familiar responses \n",
    "print(\"Familiar anova: \",stats.f_oneway(np.nansum(histData_learned,2)[:,0],np.nansum(histData_learned,2)[:,1],np.nansum(histData_learned,2)[:,2],axis=0))\n",
    "#anova between unfamiliar responses \n",
    "print(\"Unfamiliar anova: \",stats.f_oneway(np.nansum(histData_novel,2)[:,0],np.nansum(histData_novel,2)[:,1],np.nansum(histData_novel,2)[:,2],axis=0))\n",
    "#plot\n",
    "fig = plt.figure()\n",
    "#collapse across subjects\n",
    "histAllsubj_learned = np.nansum(histData_learned,0)\n",
    "histAllsubj_novel = np.nansum(histData_novel,0)\n",
    "c1 = plt.bar([0,1.5,3],[np.nansum(histAllsubj_learned[0]),np.nansum(histAllsubj_learned[1]),np.nansum(histAllsubj_learned[2])],width=.5,color='b')\n",
    "c2 = plt.bar([.5,2,3.5],[np.nansum(histAllsubj_novel[0]),np.nansum(histAllsubj_novel[1]),np.nansum(histAllsubj_novel[2])],width=.5,color='m')\n",
    "#compute error term (will be len(3) array)\n",
    "learned_hist_err = np.std(np.nansum(histData_learned,2),0)\n",
    "novel_hist_err = np.std(np.nansum(histData_novel,2),0)\n",
    "#plot\n",
    "plt.errorbar([0,.5],[np.nansum(histAllsubj_learned[0]),np.nansum(histAllsubj_novel[0])],yerr=[learned_hist_err[0],novel_hist_err[0]],color='k')\n",
    "plt.errorbar([1.5,2],[np.nansum(histAllsubj_learned[1]),np.nansum(histAllsubj_novel[1])],yerr=[learned_hist_err[1],novel_hist_err[1]],color='k')\n",
    "plt.errorbar([3,3.5],[np.nansum(histAllsubj_learned[2]),np.nansum(histAllsubj_novel[2])],yerr=[learned_hist_err[2],novel_hist_err[2]],color='k')\n",
    "plt.legend([c1,c2],['familiar','unfamiliar'])\n",
    "plt.xticks([.25,1.75,3.25],['target','competitor','noncompetitor'])\n",
    "plt.ylabel('# of responses')\n",
    "plt.title(\"Histogram of responses by condition\")\n",
    "plt.savefig(figure_dir+'response_histograms.pdf',format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3858faa2-85ea-433f-836c-15329fd1bd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot histogrm but as a mean\n",
    "totTrials = (120*nsubj)/2\n",
    "fig = plt.figure()\n",
    "#collapse across subjects\n",
    "histAllsubj_learned = np.nansum(histData_learned,0)\n",
    "histAllsubj_novel = np.nansum(histData_novel,0)\n",
    "c1 = plt.bar([0,1.5,3],[np.nansum(histAllsubj_learned[0])/totTrials,np.nansum(histAllsubj_learned[1])/totTrials,np.nansum(histAllsubj_learned[2])/totTrials],width=.5,color='b')\n",
    "c2 = plt.bar([.5,2,3.5],[np.nansum(histAllsubj_novel[0])/totTrials,np.nansum(histAllsubj_novel[1])/totTrials,np.nansum(histAllsubj_novel[2])/totTrials],width=.5,color='m')\n",
    "#compute error term (will be len(3) array)\n",
    "learned_hist_err = np.std(np.nansum(histData_learned,2)/totTrials,0)\n",
    "novel_hist_err = np.std(np.nansum(histData_novel,2)/totTrials,0)\n",
    "#plot\n",
    "plt.errorbar([0,.5],[np.nansum(histAllsubj_learned[0])/totTrials,np.nansum(histAllsubj_novel[0])/totTrials],yerr=[learned_hist_err[0],novel_hist_err[0]],color='k')\n",
    "plt.errorbar([1.5,2],[np.nansum(histAllsubj_learned[1])/totTrials,np.nansum(histAllsubj_novel[1])/totTrials],yerr=[learned_hist_err[1],novel_hist_err[1]],color='k')\n",
    "plt.errorbar([3,3.5],[np.nansum(histAllsubj_learned[2])/totTrials,np.nansum(histAllsubj_novel[2])/totTrials],yerr=[learned_hist_err[2],novel_hist_err[2]],color='k')\n",
    "plt.legend([c1,c2],['familiar','unfamiliar'])\n",
    "plt.xticks([.25,1.75,3.25],['target','competitor','noncompetitor'])\n",
    "plt.ylabel('# of responses')\n",
    "plt.title(\"Mean responses by condition\")\n",
    "plt.savefig(figure_dir+'response_means.pdf',format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23339236-2b20-46c7-8099-cf9f42d0058c",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### nback performance over blocks #######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd51ee2a-b6ab-4b80-b0f2-6271c7fce3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot nback acc as a function of blocks\n",
    "#ttest between blocks 1 and 20\n",
    "print(\"nback block acc ttest: \",stats.ttest_rel(meanAcc_nback[:,0],meanAcc_nback[:,19],nan_policy='omit'))\n",
    "#plot\n",
    "fig = plt.figure()\n",
    "plt.plot(np.arange(0,20),np.nanmean(meanAcc_nback,0),color='m',linewidth=3)\n",
    "#error is sem\n",
    "plt.errorbar(np.arange(0,20),np.nanmean(meanAcc_nback,0),yerr=np.nanstd(meanAcc_nback,0)/np.sqrt(nsubj),color='k',capsize=3)\n",
    "plt.yticks([0.5,0.6,0.7,0.8,0.9,1],[50,60,70,80,90,100])\n",
    "#plt.scatter([0.5,2.5,9.5],[1,1,1],marker='*',color='k')\n",
    "plt.ylabel('accuracy (%)')\n",
    "plt.xlabel('block number')\n",
    "plt.xticks([0,5,10,15,20])\n",
    "plt.title('nback mean accuracy by block')\n",
    "plt.savefig(figure_dir+'nback_acc_blockwise.pdf',format='pdf')\n",
    "plt.show()\n",
    "#subjects messed up the bottons 2x\n",
    "#block 14 was caused by subj13\n",
    "#block 20 was caused by subj3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25d26c3-2e31-472f-94fe-53a6cc9f2ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RTs, cause why not\n",
    "#ttest between blocks 1 and 20\n",
    "print(\"nback block rt ttest: \",stats.ttest_rel(meanRT_nback[:,0],meanRT_nback[:,19],nan_policy='omit'))\n",
    "fig = plt.figure()\n",
    "plt.plot(np.arange(0,20),np.nanmean(meanRT_nback,0),color='m',linewidth=3)\n",
    "#error is std\n",
    "plt.errorbar(np.arange(0,20),np.nanmean(meanRT_nback,0),yerr=np.nanstd(meanRT_nback,0)/np.sqrt(nsubj),color='k',capsize=3)\n",
    "plt.yticks([0.5,0.6,0.7,0.8],[500,600,700,800])\n",
    "#plt.scatter([0.5,2.5,9.5],[1,1,1],marker='*',color='k')\n",
    "plt.ylabel('RT (ms)')\n",
    "plt.xlabel('block number')\n",
    "plt.xticks([0,5,10,15,20])\n",
    "plt.title('nback mean response time by block')\n",
    "plt.savefig(figure_dir+'nback_rt_blockwise.pdf',format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffaebc4-76e3-415d-94b5-840007085dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### correlations between nback performance and association acc ########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2beb5c99-8266-4876-9219-562e28421d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#across subject correlation of nback acc and learned acc\n",
    "#remove nans from data\n",
    "clean_meanAcc_nback = meanAcc_nback[~np.isnan(meanAcc_nback[:,1])]\n",
    "clean_meanAcc_novel = meanAcc_novel[~np.isnan(meanAcc_novel[:,1])]\n",
    "clean_meanAcc_learned = meanAcc_learned[~np.isnan(meanAcc_learned[:,1])]\n",
    "[r,p] = stats.pearsonr(np.nanmean(clean_meanAcc_nback,1),np.nanmean(clean_meanAcc_learned,1))\n",
    "print(\"Pearson r of across subject correlation of nback and familiar acc: \",np.round(r,5),np.round(p,5))\n",
    "[m,b] = np.polyfit(np.nanmean(clean_meanAcc_nback,1),np.nanmean(clean_meanAcc_learned,1),1)\n",
    "fig = plt.figure()\n",
    "plt.scatter(np.nanmean(clean_meanAcc_nback,1),np.nanmean(clean_meanAcc_learned,1),color='gray')\n",
    "plt.plot(np.nanmean(clean_meanAcc_nback,1),m*np.nanmean(clean_meanAcc_nback,1)+b,color='m')\n",
    "plt.xlabel('mean nback accuracy (%)')\n",
    "plt.ylabel('mean learned stimulus accuracy (%)')\n",
    "plt.yticks([.2,.3,.4,.5,.6,.7,.8,.9],[20,30,40,50,60,70,80,90])\n",
    "plt.xticks([.65,.7,.75,.8,.85,.9,.95],[65,70,75,80,85,90,95])\n",
    "plt.title('nback and learned stimulus accuracy correlation\\nr = '+str(np.round(r,2)))\n",
    "plt.savefig(figure_dir+'famAcc_correlation.pdf',format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7f92c9-cb50-451e-b4b8-3cc10085856e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#across subject correlation of nback and novel acc\n",
    "[r,p] = stats.pearsonr(np.nanmean(clean_meanAcc_nback,1),np.nanmean(clean_meanAcc_novel,1))\n",
    "print(\"Pearson r of across subject correlation of nback and unfamiliar acc: \",np.round(r,5),np.round(p,5))\n",
    "[m,b] = np.polyfit(np.nanmean(clean_meanAcc_nback,1),np.nanmean(clean_meanAcc_novel,1),1)\n",
    "fig = plt.figure()\n",
    "plt.scatter(np.nanmean(clean_meanAcc_nback,1),np.nanmean(clean_meanAcc_novel,1),color='gray')\n",
    "plt.plot(np.nanmean(clean_meanAcc_nback,1),m*np.nanmean(clean_meanAcc_nback,1)+b,color='m')\n",
    "plt.xlabel('mean nback accuracy (%)')\n",
    "plt.ylabel('mean novel stimulus accuracy (%)')\n",
    "plt.yticks([.2,.3,.4,.5,.6,.7,.8,.9],[20,30,40,50,60,70,80,90])\n",
    "plt.xticks([.65,.7,.75,.8,.85,.9,.95],[65,70,75,80,85,90,95])\n",
    "plt.title('nback and novel stimulus accuracy correlation\\nr = '+str(np.round(r,2)))\n",
    "plt.savefig(figure_dir+'unfamAcc_correlation.pdf',format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf0393b-2560-4001-8264-4888264dd247",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Look at response times for the association task #######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646d3e19-7c20-4d26-bc36-99e5e52fa0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot rts for study test\n",
    "print(\"Familiar rts = \"+str(np.nanmean(meanRT_learned)),\" Unfamiliar rts = \"+str(np.nanmean(meanRT_novel)))\n",
    "#ttest of mean accuracy distributions between familiar and unfamiliar stimuli\n",
    "print(\"Familiar vs unfamiliar rt ttest: \",np.round(stats.ttest_rel(np.nanmean(meanRT_learned,1),np.nanmean(meanRT_novel,1),nan_policy='omit'),6))\n",
    "#plot difference between familiar and unfamiliar accuracy means\n",
    "fig = plt.figure()\n",
    "plt.bar([0,1],[np.nanmean(meanRT_learned),np.nanmean(meanRT_novel)],color=['blue','m'])\n",
    "#error term is SEM\n",
    "plt.errorbar([0,1],[np.nanmean(meanRT_learned),np.nanmean(meanRT_novel)],yerr=[np.nanstd(np.nanmean(meanRT_learned,1))/np.sqrt(nsubj),np.nanstd(np.nanmean(meanRT_novel,1))/np.sqrt(nsubj)],color='k')\n",
    "plt.xlabel(\"stimulus condition\")\n",
    "plt.xticks([0,1],[\"familiar\",\"unfamiliar\"])\n",
    "plt.ylabel(\"mean RTs (ms)\")\n",
    "plt.yticks([0,.3,.6,.9,1.2,1.5],[0,300,600,900,1200,1500])\n",
    "plt.title(\"Mean RT by condition\")\n",
    "#plt.scatter([0.5],[1.5],marker='*',color='k')\n",
    "plt.savefig(figure_dir+'rt_diff_familiar_vs_nonfamiliar.pdf',format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbeda08-d239-4ca7-966b-0e80cdda45f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot mean respone times split by responses\n",
    "print(\"Familiar vs unfamiliar target rt ttest: \",np.round(stats.ttest_rel(np.mean(rtData_learned,2)[:,0],np.mean(rtData_novel,2)[:,0],nan_policy='omit'),6))\n",
    "#ttest between familiar and unfamiliar competitor\n",
    "print(\"Familiar vs unfamiliar competitor rt ttest: \",np.round(stats.ttest_rel(np.mean(rtData_learned,2)[:,1],np.mean(rtData_novel,2)[:,1],nan_policy='omit'),6))\n",
    "#ttest between familiar and unfamiliar noncompetitor\n",
    "print(\"Familiar vs unfamiliar noncompetitor rt ttest: \",np.round(stats.ttest_rel(np.mean(rtData_learned,2)[:,2],np.mean(rtData_novel,2)[:,2],nan_policy = 'omit'),6))\n",
    "#anova between familiar responses \n",
    "print(\"Familiar anova: \",stats.f_oneway(nan_scrub(np.nansum(rtData_learned,2)[:,0]),nan_scrub(np.nanmean(rtData_learned,2)[:,1]),nan_scrub(np.nanmean(rtData_learned,2)[:,2],axis=0)))\n",
    "#anova between unfamiliar responses \n",
    "print(\"Unfamiliar anova: \",stats.f_oneway(nan_scrub(np.nansum(rtData_novel,2)[:,0]),nan_scrub(np.nanmean(rtData_novel,2)[:,1]),nan_scrub(np.nanmean(rtData_novel,2)[:,2],axis=0)))\n",
    "fig = plt.figure()\n",
    "#collapse across subjects\n",
    "rtData_learned_blockmean = np.nanmean(rtData_learned,2)\n",
    "rtData_novel_blockmean = np.nanmean(rtData_novel,2)\n",
    "c1 = plt.bar([0,1.5,3],[np.nanmean(rtData_learned_blockmean[:,0]),np.nanmean(rtData_learned_blockmean[:,1]),np.nanmean(rtData_learned_blockmean[:,2])],width=.5,color='b')\n",
    "c2 = plt.bar([.5,2,3.5],[np.nanmean(rtData_novel_blockmean[:,0]),np.nanmean(rtData_novel_blockmean[:,1]),np.nanmean(rtData_novel_blockmean[:,2])],width=.5,color='m')\n",
    "#compute error term (will be len(3) array)\n",
    "learned_rt_err = np.nanstd(rtData_learned_blockmean,0)/np.sqrt(nsubj)\n",
    "novel_rt_err = np.nanstd(rtData_novel_blockmean,0)/np.sqrt(nsubj)\n",
    "#plot\n",
    "plt.errorbar([0,.5],[np.nanmean(rtData_learned_blockmean[:,0]),np.nanmean(rtData_novel_blockmean[:,0])],yerr=[learned_rt_err[0],novel_rt_err[0]],color='k')\n",
    "plt.errorbar([1.5,2],[np.nanmean(rtData_learned_blockmean[:,1]),np.nanmean(rtData_novel_blockmean[:,1])],yerr=[learned_rt_err[1],novel_rt_err[1]],color='k')\n",
    "plt.errorbar([3,3.5],[np.nanmean(rtData_learned_blockmean[:,2]),np.nanmean(rtData_novel_blockmean[:,2])],yerr=[learned_rt_err[2],novel_rt_err[2]],color='k')\n",
    "plt.legend([c1,c2],['familiar','unfamiliar'])\n",
    "plt.xticks([.25,1.75,3.25],['target','competitor','noncompetitor'])\n",
    "plt.ylabel('mean rt (s)')\n",
    "plt.title(\"Mean response times by condition\")\n",
    "plt.savefig(figure_dir+'responsetime_means.pdf',format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ddc900-9042-4e4c-a0a8-f320c4d490d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Look at blockwise performance on the association task ########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb46a30a-8917-407a-b73d-b5004e206935",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ttests between condition means per block\n",
    "print(\"Familiar vs unfamiliar block 1 acc ttest: \",np.round(stats.ttest_rel(meanAcc_learned[:,0],meanAcc_novel[:,0],nan_policy='omit'),6))\n",
    "print(\"Familiar vs unfamiliar block 2 acc ttest: \",np.round(stats.ttest_rel(meanAcc_learned[:,1],meanAcc_novel[:,1],nan_policy='omit'),6))\n",
    "print(\"Familiar vs unfamiliar block 3 acc ttest: \",np.round(stats.ttest_rel(meanAcc_learned[:,2],meanAcc_novel[:,2],nan_policy='omit'),6))\n",
    "#plot the mean accuracy by block\n",
    "fig = plt.figure()\n",
    "c1 = plt.bar([0,1.5,3],np.nanmean(meanAcc_learned,0),width=.5,color='b')\n",
    "c2 = plt.bar([.5,2,3.5],np.nanmean(meanAcc_novel,0),width=.5,color='m')\n",
    "plt.errorbar([0,.5],[np.nanmean(meanAcc_learned,0)[0],np.nanmean(meanAcc_novel,0)[0]],yerr=[np.nanstd(meanAcc_learned,0)[0]/np.sqrt(nsubj),np.nanstd(meanAcc_novel,0)[0]/np.sqrt(nsubj)],color='k')\n",
    "plt.errorbar([1.5,2],[np.nanmean(meanAcc_learned,0)[1],np.nanmean(meanAcc_novel,0)[1]],yerr=[np.nanstd(meanAcc_learned,0)[1]/np.sqrt(nsubj),np.nanstd(meanAcc_novel,0)[1]/np.sqrt(nsubj)],color='k')\n",
    "plt.errorbar([3,3.5],[np.nanmean(meanAcc_learned,0)[2],np.nanmean(meanAcc_novel,0)[2]],yerr=[np.nanstd(meanAcc_learned,0)[2]/np.sqrt(nsubj),np.nanstd(meanAcc_novel,0)[2]/np.sqrt(nsubj)],color='k')\n",
    "plt.xlabel('block #')\n",
    "plt.xticks([.25,1.75,3.25],[1,2,3])\n",
    "plt.ylabel('accuracy (%)')\n",
    "plt.yticks([.1,.2,.3,.4,.5,.6,.7,.8],[10,20,30,40,50,60,70,80])\n",
    "plt.legend([c1,c2],['familiar','unfamiliar'])\n",
    "plt.savefig(figure_dir+'assoc_acc_by_block.pdf',format='pdf')\n",
    "plt.show()\n",
    "print(np.nanmean(meanAcc_learned[:,2]),np.nanmean(meanAcc_novel[:,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ba6ef2-c631-45d5-9986-2d1ca5c53ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exclude underperformers in the first block\n",
    "n = np.sum(fb_select)\n",
    "print(\"first block n = \",str(n))\n",
    "print(\"first block acc cutoff = \",str(fb_cutoff))\n",
    "fb_select = fb_select.astype(int)\n",
    "print(\"Familiar vs unfamiliar block 1 acc ttest: \",np.round(stats.ttest_rel(meanAcc_learned[fb_select,0],meanAcc_novel[fb_select,0],nan_policy='omit'),6))\n",
    "#plot the mean accuracy by block\n",
    "fig = plt.figure()\n",
    "plt.bar([0,1],[np.nanmean(meanAcc_learned[fb_select,0]),np.nanmean(meanAcc_novel[fb_select,0])],width=.5,color=['b','m'])\n",
    "plt.errorbar([0,1],[np.nanmean(meanAcc_learned[fb_select,0]),np.nanmean(meanAcc_novel[fb_select,0])],yerr=[np.nanstd(meanAcc_learned[fb_select,0])/np.sqrt(n),np.nanstd(meanAcc_novel[fb_select,0])/np.sqrt(n)],color='k')\n",
    "plt.xlabel(\"stimulus condition\")\n",
    "plt.xticks([0,1],[\"familiar\",\"unfamiliar\"])\n",
    "plt.ylabel(\"mean block 1 acc\")\n",
    "plt.yticks([.1,.2,.3,.4,.5,.6,.7,.8],[10,20,30,40,50,60,70,80])\n",
    "plt.title(\"Mean block 1 accuracy difference\")\n",
    "#plt.scatter([0.5],[1.5],marker='*',color='k')\n",
    "plt.savefig(figure_dir+'acc_first_block_exclusion.pdf',format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492497e5-9b52-4abb-b84c-c96af3aa5f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at competitor vs noncompetitor\n",
    "blockTrials = (40*nsubj)/2\n",
    "histAllsubj_learned = np.nansum(histData_learned,0)\n",
    "histAllsubj_novel = np.nansum(histData_novel,0)\n",
    "fig = plt.figure()\n",
    "c1 = plt.bar([0,2.5,5],histAllsubj_learned[1]/blockTrials,color='b',width=.5)\n",
    "c2 = plt.bar([1,3.5,6],histAllsubj_learned[2]/blockTrials,color='b',width=.5)\n",
    "c3 = plt.bar([.5,3,5.5],histAllsubj_novel[1]/blockTrials,color='m',width=.5)\n",
    "c4 = plt.bar([1.5,4,6.5],histAllsubj_novel[2]/blockTrials,color='m',width=.5)\n",
    "learned_hist_err = np.nanstd(histData_learned/40,0)/np.sqrt(nsubj)\n",
    "novel_hist_err = np.nanstd(histData_novel/40,0)/np.sqrt(nsubj)\n",
    "plt.errorbar([0,.5],[histAllsubj_learned[1,0]/blockTrials,histAllsubj_novel[1,0]/blockTrials],yerr=[learned_hist_err[1,0],novel_hist_err[1,0]],color='k')\n",
    "plt.errorbar([1,1.5],[histAllsubj_learned[2,0]/blockTrials,histAllsubj_novel[2,0]/blockTrials],yerr=[learned_hist_err[2,0],novel_hist_err[2,0]],color='k')\n",
    "plt.errorbar([2.5,3],[histAllsubj_learned[1,1]/blockTrials,histAllsubj_novel[1,1]/blockTrials],yerr=[learned_hist_err[1,1],novel_hist_err[1,1]],color='k')\n",
    "plt.errorbar([3.5,4],[histAllsubj_learned[2,1]/blockTrials,histAllsubj_novel[2,1]/blockTrials],yerr=[learned_hist_err[2,1],novel_hist_err[2,1]],color='k')\n",
    "plt.errorbar([5,5.5],[histAllsubj_learned[1,2]/blockTrials,histAllsubj_novel[1,2]/blockTrials],yerr=[learned_hist_err[1,2],novel_hist_err[1,2]],color='k')\n",
    "plt.errorbar([6,6.5],[histAllsubj_learned[2,2]/blockTrials,histAllsubj_novel[2,2]/blockTrials],yerr=[learned_hist_err[2,2],novel_hist_err[2,2]],color='k')\n",
    "plt.xticks([.25,1.25,2.75,3.75,5.25,6.25],['comp','noncomp','comp','noncomp','comp','noncomp'])\n",
    "plt.yticks([0,.05,.1,.15,.2,.25,.3],[0,5,10,15,20,25,30])\n",
    "plt.ylabel(\"accuracy (%)\")\n",
    "plt.legend([c1,c3],['familiar','unfamiliar'])\n",
    "plt.savefig(figure_dir+'comp_vs_nocomp_blockwise.pdf',format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3500c4-9647-4938-b09d-dea5e2b87f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### check that gazebos arent just easier to learn than beaches ######\n",
    "print('beachs vs gaxebos ttest: ',stats.ttest_rel(np.nanmean(meanAcc_learned[category_learned==0],1),np.nanmean(meanAcc_learned[category_learned==1],1),nan_policy='omit'))\n",
    "fig = plt.figure()\n",
    "plt.bar([0,1],[np.nanmean(meanAcc_learned[category_learned==0]),np.nanmean(meanAcc_learned[category_learned==1])],color=['b','g'])\n",
    "plt.errorbar([0,1],[np.nanmean(meanAcc_learned[category_learned==0]),np.nanmean(meanAcc_learned[category_learned==1])],yerr=[np.nanstd(np.nanmean(meanAcc_learned[category_learned==0],1),0)/np.sqrt(nsubj),np.nanstd(np.nanmean(meanAcc_learned[category_learned==1],1),0)/np.sqrt(nsubj)])\n",
    "plt.xticks([0,1],['beaches','gazebos'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4ea5ac-c3ef-4edc-b11b-bc7d969ac648",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.system('jupyter nbconvert --to html marshmalloogalooAnalysis.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a28096-96f2-4da6-895f-020677cfe93a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d562008e-ef93-4709-b3b5-ffe0fed4ccd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3308ce1c-6865-40d6-9999-c1f9c3ad630b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c5e47d-b12e-4afc-919d-08c735c3eca9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9a5177-d403-4a2d-92a2-fdf9ad8c930b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085b48c5-717b-405e-a2a5-9a3be8cf9d9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172f7a68-b27b-4a30-a756-9f9e4f2ae0fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cadfef4-4908-44c5-b836-acda991f9efa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
